{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66c0df0e",
   "metadata": {},
   "source": [
    "### **APIs with Python: Google Sheets Monitoring - Cocaine Seizures**\n",
    "#### InSight Crime’s MAD Unit - (June, 2025)\n",
    "\n",
    "##### Luis Felipe Villota Macías\n",
    "\n",
    "---------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c506f4d0",
   "metadata": {},
   "source": [
    "### 1. Goals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0817cb81",
   "metadata": {},
   "source": [
    "* Monitor and validate data in a shared Google Sheet using automated checks to ensure accuracy, consistency, and data quality.\n",
    "\n",
    "* Highlight invalid or suspicious entries directly in the sheet and optionally generate weekly reports to support governance and oversight.\n",
    "\n",
    "* Automate the process with Google Apps Script or Python, running validations on a schedule (e.g. every Friday) with minimal manual effort.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d6e936",
   "metadata": {},
   "source": [
    "### 2. Project Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac164b48",
   "metadata": {},
   "source": [
    "#### 2.1 Version Control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7255ac",
   "metadata": {},
   "source": [
    "I decided to create a single GitHub repository ([FelipeVillota/db-check-cocaine-seizures](https://github.com/FelipeVillota/db-check-cocaine-seizures)). I keep the repository `private` with the possibility to give access to the online repo at any time. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad16f5b0",
   "metadata": {},
   "source": [
    "#### 2.2 Reproducible Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1112678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT\n",
    "# To create venv\n",
    "# python -m venv venv-scraping \n",
    "\n",
    "# To activate environment, run in Terminal:\n",
    "# # (optional, temporary auth) \n",
    "# Set-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass \n",
    "# venv-scraping\\Scripts\\activate\n",
    "\n",
    "# Then select respective kernel --> also install ipykernel package to connect to kernel\n",
    "\n",
    "# Update list master list\n",
    "# pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898046a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\Desktop\\codebaker\\all_multi\\ic-ct\\apis\\venv-apis\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "# Checking venv-apis works\n",
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802dc17a",
   "metadata": {},
   "source": [
    "#### 2.3 Loading Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a957b9",
   "metadata": {},
   "source": [
    "pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "735fe917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76b22df",
   "metadata": {},
   "source": [
    "----------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d515b3",
   "metadata": {},
   "source": [
    "### 3.  Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6ab109",
   "metadata": {},
   "source": [
    "As general background and scheme, \n",
    "\n",
    "* I conceive an API as a portal that communicates data between different software systems, so it is key to know how to make `requests` (queries) to different `endpoints` (particular URLs as gateways of the API) to extract data and to know the level of `authentication` (permissions) required to access instances (Goodwin, 2024). Additionally, one has to consider the `status` (success or not) of the eventual `response` and the `data format` of the output (to be processed later) (Goodwin, 2024; IBM Technology, 2020).\n",
    "\n",
    "* To interact with any API effectively, I try to get familiar with the developer's documentation (in this case also dataset codebooks). This is the guide to how the API works and how I can use its functionalities -it explains the protocols for accessing different software applications, making calls and receiving responses.\n",
    "\n",
    "* In this case, the UCDP API is `openly available` and has a `REStful architecture` (Representational State Transfer, a client-server dynamic). This is a standard design and it means it uses `HTTP` (Hypertext Transfer Protocol) communication methods (IBM Technology, 2020). So, the `requests` (queries or petitions to the source) are made via operations under the CRUD logic (create, read, update, delete) (ibid).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d787c08b",
   "metadata": {},
   "source": [
    "\n",
    "* I identify that the UCDP API basics are : \n",
    "\n",
    "    Base URL: `https://ucdpapi.pcr.uu.se/api/`\n",
    "\n",
    "    Endpoint structure (RESTful format): `https://ucdpapi.pcr.uu.se/api/<resource>/<version>?<pagesize=x>&<page=x>`\n",
    "\n",
    "    Where the parameters are: \n",
    "\n",
    "    Target dataset: `<resource>` to be replaced with `gedevents` for the UCDP Georeferenced Event Dataset - GED\n",
    "\n",
    "    Dataset version: `<version>` to be replaced with `24.1` which is the latest and yearly release is `24.01.24.12`\n",
    "\n",
    "    Pagination parameters: `<pagesize=x>&<page=x>` \n",
    "\n",
    "    Format of requested data: `JSON` an array of objects (common notation in APIs, representing GED events)\n",
    "\n",
    "\n",
    "* And, regarding rate limits (focusing on `gedevents`):\n",
    "\n",
    "    `Requires paging:  1 to 1,000 rows per page`\n",
    "\n",
    "    `Allows 5,000 requests/day`\n",
    "\n",
    "    `Counters reset at midnight (UTC)`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5904545",
   "metadata": {},
   "source": [
    "* My general idea for this exercise is to create a modular client (frontend) call that extracts just the subset of data required from the UCDP API server (backend) to answer the questions; -and, make it easily reusable for future queries.\n",
    "\n",
    "```python\n",
    "\n",
    "MAIN SCRIPT\n",
    "\n",
    "# API call \n",
    "# Creating a request to extract and analyze conflict data for:\n",
    "    # Deadliest municipalities (overall and civilians) in 2024\n",
    "    # Provincial violence changes (max increase and max decrease) since Dec 2023\n",
    "# Establish parameters (ex. pagination 1000 records/page)\n",
    "# Establish cache to avoid duplicate calls\n",
    "\n",
    "# Key objects\n",
    "base_UCDP_API_url = \"URL\"\n",
    "\n",
    "# Focus\n",
    "target_dataset = \"dataset\" # gedevents\n",
    "\n",
    "# Accommodating different versions to filter from\n",
    "dataset_versions={\n",
    "  \"official\",  \n",
    "  \"candidate_yearly\",\n",
    "  \"candidate_monthly\"}\n",
    "\n",
    "# Date filters, under UCDP API logic \n",
    "dates_full_2024:{\n",
    "        'startdate': \"YYYY-MM-DD\",\n",
    "        'enddate': \"YYYY-MM-DD\",\n",
    " }\n",
    "dates_since_dec_2023: {\n",
    "        'startdate': \"YYYY-MM-DD\",\n",
    "}\n",
    "\n",
    "# Further conditions can be defined here too (ex: Id, Country, Dyad, etc)\n",
    "\n",
    "# Set of functions:\n",
    "\n",
    "FUNCTION build_api_url(target_dataset, dataset_versions, parameters=x, conditions=z):\n",
    "    # Construct the body of a custom URL with all relevant objects (empty and concatenated) and store it\n",
    "    # Returns a \"generic\" endpoint URL (which is going to store future inputs)\n",
    "   \n",
    "FUNCTION get_data(build_api_url):\n",
    "    # Use the modular endpoint structure\n",
    "    # Making initial GET request operation by overwriting the model endpoint URL by,\n",
    "        # LOOPING for the desired filtering instances (dataset_versions, conditions)\n",
    "            # WHILE they exist\n",
    "        # Check response status, print\n",
    "        # Store JSON data from a succesful response\n",
    "    # Return responses (subsets of UCDP data) as df objects\n",
    "    # The broad logic would be something like\n",
    "    data_2024 = get_data(build_api_url(dataset_versions, (\"startdate\":\"2024-01-01\", \"enddate\": \"2024-12-31\"))) # plus other filters\n",
    "    data_dec2023 = get_data(build_api_url(dataset_versions, (\"startdate\":\"2023-12-01\"))) # plus other filters\n",
    "\n",
    "\n",
    "# Data Analysis\n",
    "\n",
    "# Filter each df by the different date ranges and conditionals (can be applied before or here)\n",
    "# Group by adm_1, adm_2 in respective date-filtered df\n",
    "# Sum fatalities or count unique events in each according to the question\n",
    "# Sort by descending results of those metrics (or select desired cases for min or max values)\n",
    "# Print results\n",
    "\n",
    "# (NOTE: I keep the latter rationale here as simple as possible. After exploring the dataset versions and respective date ranges I considered different combinations (filters, merges of df) to approach the questions. Please see respective comments below.)\n",
    "```\n",
    "____________________"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b99eeee",
   "metadata": {},
   "source": [
    "### 4. Execution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690419cc",
   "metadata": {},
   "source": [
    "Step-by-step implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db308e65",
   "metadata": {},
   "source": [
    "#### 4.1 Accessing the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d79640",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining constant vars \n",
    "site = \"https://ucdpapi.pcr.uu.se/api/\"\n",
    "resource_dataset = \"gedevents\"\n",
    "version = {\n",
    "    \"latest_dataset\": \"24.1\",  # Official yearly release, covers events from 1989-01-01 up until 2023-12-31\n",
    "    \"candidate_yearly_dataset\": \"24.01.24.12\"  # Yearly candidate, includes full 2024\n",
    "}\n",
    "pag_max = 1000  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f7d308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ucdpapi.pcr.uu.se/api/gedevents/24.1?pagesize=1000&page=1&StartDate=2020-01-01&EndDate=2020-12-31\n"
     ]
    }
   ],
   "source": [
    "# Building a general function that constructs a full endpoint URL\n",
    "def ucdp_api_url(version=None, start_date=None, end_date=None, page=1):\n",
    "    url = f\"{site}{resource_dataset}/{version}?pagesize={pag_max}&page={page}\"\n",
    "    if start_date:\n",
    "        url += f\"&StartDate={start_date}\"\n",
    "    if end_date:\n",
    "        url += f\"&EndDate={end_date}\"\n",
    "    return url\n",
    "\n",
    "# Just an example of the output:\n",
    "print(ucdp_api_url(version=\"24.1\", start_date=\"2020-01-01\", end_date=\"2020-12-31\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470d3650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to get results accommodating a combined filter (version + dates)\n",
    "\n",
    "def get_filtered_data(version=None, start_date=None, end_date=None):\n",
    "    \n",
    "    print(f\"\\nUCDP GED data from version {version} between {start_date} and {end_date if end_date else 'latest'}\")\n",
    "    \n",
    "    all_data = []\n",
    "    page = 1\n",
    "\n",
    "    while True:\n",
    "        \n",
    "        url = ucdp_api_url(version=version, start_date=start_date, end_date=end_date, page=page) # Overwriting to later input desired values\n",
    "        response = requests.get(url) # Calling the API endpoint\n",
    "        \n",
    "        if response.status_code != 200: # If not succesful\n",
    "            raise Exception(f\"Request failed on page {page} with status {response.status_code}\") # Why it was not succesful\n",
    "        \n",
    "        data = response.json().get(\"Result\", []) # Storing JSON data\n",
    "        all_data.extend(data) # appending\n",
    "\n",
    "        print(f\"Fetched page {page} with {len(data)} records.\") # Helping report fetched data\n",
    "        if len(data) < pag_max:\n",
    "            break\n",
    "        page += 1\n",
    "\n",
    "    return pd.DataFrame(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3ec1a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "UCDP GED data from version 24.1 between None and latest\n",
      "Fetched page 1 with 1000 records.\n",
      "Fetched page 2 with 1000 records.\n",
      "Fetched page 3 with 1000 records.\n",
      "Fetched page 4 with 1000 records.\n",
      "Fetched page 5 with 1000 records.\n",
      "Fetched page 6 with 1000 records.\n",
      "Fetched page 7 with 1000 records.\n",
      "Fetched page 8 with 1000 records.\n",
      "Fetched page 9 with 1000 records.\n",
      "Fetched page 10 with 1000 records.\n",
      "Fetched page 11 with 1000 records.\n",
      "Fetched page 12 with 1000 records.\n",
      "Fetched page 13 with 1000 records.\n",
      "Fetched page 14 with 1000 records.\n",
      "Fetched page 15 with 1000 records.\n",
      "Fetched page 16 with 1000 records.\n",
      "Fetched page 17 with 1000 records.\n",
      "Fetched page 18 with 1000 records.\n",
      "Fetched page 19 with 1000 records.\n",
      "Fetched page 20 with 1000 records.\n",
      "Fetched page 21 with 1000 records.\n",
      "Fetched page 22 with 1000 records.\n",
      "Fetched page 23 with 1000 records.\n",
      "Fetched page 24 with 1000 records.\n",
      "Fetched page 25 with 1000 records.\n",
      "Fetched page 26 with 1000 records.\n",
      "Fetched page 27 with 1000 records.\n",
      "Fetched page 28 with 1000 records.\n",
      "Fetched page 29 with 1000 records.\n",
      "Fetched page 30 with 1000 records.\n",
      "Fetched page 31 with 1000 records.\n",
      "Fetched page 32 with 1000 records.\n",
      "Fetched page 33 with 1000 records.\n",
      "Fetched page 34 with 1000 records.\n",
      "Fetched page 35 with 1000 records.\n",
      "Fetched page 36 with 1000 records.\n",
      "Fetched page 37 with 1000 records.\n",
      "Fetched page 38 with 1000 records.\n",
      "Fetched page 39 with 1000 records.\n",
      "Fetched page 40 with 1000 records.\n",
      "Fetched page 41 with 1000 records.\n",
      "Fetched page 42 with 1000 records.\n",
      "Fetched page 43 with 1000 records.\n",
      "Fetched page 44 with 1000 records.\n",
      "Fetched page 45 with 1000 records.\n",
      "Fetched page 46 with 1000 records.\n",
      "Fetched page 47 with 1000 records.\n",
      "Fetched page 48 with 1000 records.\n",
      "Fetched page 49 with 1000 records.\n",
      "Fetched page 50 with 1000 records.\n",
      "Fetched page 51 with 1000 records.\n",
      "Fetched page 52 with 1000 records.\n",
      "Fetched page 53 with 1000 records.\n",
      "Fetched page 54 with 1000 records.\n",
      "Fetched page 55 with 1000 records.\n",
      "Fetched page 56 with 1000 records.\n",
      "Fetched page 57 with 1000 records.\n",
      "Fetched page 58 with 1000 records.\n",
      "Fetched page 59 with 1000 records.\n",
      "Fetched page 60 with 1000 records.\n",
      "Fetched page 61 with 1000 records.\n",
      "Fetched page 62 with 1000 records.\n",
      "Fetched page 63 with 1000 records.\n",
      "Fetched page 64 with 1000 records.\n",
      "Fetched page 65 with 1000 records.\n",
      "Fetched page 66 with 1000 records.\n",
      "Fetched page 67 with 1000 records.\n",
      "Fetched page 68 with 1000 records.\n",
      "Fetched page 69 with 1000 records.\n",
      "Fetched page 70 with 1000 records.\n",
      "Fetched page 71 with 1000 records.\n",
      "Fetched page 72 with 1000 records.\n",
      "Fetched page 73 with 1000 records.\n",
      "Fetched page 74 with 1000 records.\n",
      "Fetched page 75 with 1000 records.\n",
      "Fetched page 76 with 1000 records.\n",
      "Fetched page 77 with 1000 records.\n",
      "Fetched page 78 with 1000 records.\n",
      "Fetched page 79 with 1000 records.\n",
      "Fetched page 80 with 1000 records.\n",
      "Fetched page 81 with 1000 records.\n",
      "Fetched page 82 with 1000 records.\n",
      "Fetched page 83 with 1000 records.\n",
      "Fetched page 84 with 1000 records.\n",
      "Fetched page 85 with 1000 records.\n",
      "Fetched page 86 with 1000 records.\n",
      "Fetched page 87 with 1000 records.\n",
      "Fetched page 88 with 1000 records.\n",
      "Fetched page 89 with 1000 records.\n",
      "Fetched page 90 with 1000 records.\n",
      "Fetched page 91 with 1000 records.\n",
      "Fetched page 92 with 1000 records.\n",
      "Fetched page 93 with 1000 records.\n",
      "Fetched page 94 with 1000 records.\n",
      "Fetched page 95 with 1000 records.\n",
      "Fetched page 96 with 1000 records.\n",
      "Fetched page 97 with 1000 records.\n",
      "Fetched page 98 with 1000 records.\n",
      "Fetched page 99 with 1000 records.\n",
      "Fetched page 100 with 1000 records.\n",
      "Fetched page 101 with 1000 records.\n",
      "Fetched page 102 with 1000 records.\n",
      "Fetched page 103 with 1000 records.\n",
      "Fetched page 104 with 1000 records.\n",
      "Fetched page 105 with 1000 records.\n",
      "Fetched page 106 with 1000 records.\n",
      "Fetched page 107 with 1000 records.\n",
      "Fetched page 108 with 1000 records.\n",
      "Fetched page 109 with 1000 records.\n",
      "Fetched page 110 with 1000 records.\n",
      "Fetched page 111 with 1000 records.\n",
      "Fetched page 112 with 1000 records.\n",
      "Fetched page 113 with 1000 records.\n",
      "Fetched page 114 with 1000 records.\n",
      "Fetched page 115 with 1000 records.\n",
      "Fetched page 116 with 1000 records.\n",
      "Fetched page 117 with 1000 records.\n",
      "Fetched page 118 with 1000 records.\n",
      "Fetched page 119 with 1000 records.\n",
      "Fetched page 120 with 1000 records.\n",
      "Fetched page 121 with 1000 records.\n",
      "Fetched page 122 with 1000 records.\n",
      "Fetched page 123 with 1000 records.\n",
      "Fetched page 124 with 1000 records.\n",
      "Fetched page 125 with 1000 records.\n",
      "Fetched page 126 with 1000 records.\n",
      "Fetched page 127 with 1000 records.\n",
      "Fetched page 128 with 1000 records.\n",
      "Fetched page 129 with 1000 records.\n",
      "Fetched page 130 with 1000 records.\n",
      "Fetched page 131 with 1000 records.\n",
      "Fetched page 132 with 1000 records.\n",
      "Fetched page 133 with 1000 records.\n",
      "Fetched page 134 with 1000 records.\n",
      "Fetched page 135 with 1000 records.\n",
      "Fetched page 136 with 1000 records.\n",
      "Fetched page 137 with 1000 records.\n",
      "Fetched page 138 with 1000 records.\n",
      "Fetched page 139 with 1000 records.\n",
      "Fetched page 140 with 1000 records.\n",
      "Fetched page 141 with 1000 records.\n",
      "Fetched page 142 with 1000 records.\n",
      "Fetched page 143 with 1000 records.\n",
      "Fetched page 144 with 1000 records.\n",
      "Fetched page 145 with 1000 records.\n",
      "Fetched page 146 with 1000 records.\n",
      "Fetched page 147 with 1000 records.\n",
      "Fetched page 148 with 1000 records.\n",
      "Fetched page 149 with 1000 records.\n",
      "Fetched page 150 with 1000 records.\n",
      "Fetched page 151 with 1000 records.\n",
      "Fetched page 152 with 1000 records.\n",
      "Fetched page 153 with 1000 records.\n",
      "Fetched page 154 with 1000 records.\n",
      "Fetched page 155 with 1000 records.\n",
      "Fetched page 156 with 1000 records.\n",
      "Fetched page 157 with 1000 records.\n",
      "Fetched page 158 with 1000 records.\n",
      "Fetched page 159 with 1000 records.\n",
      "Fetched page 160 with 1000 records.\n",
      "Fetched page 161 with 1000 records.\n",
      "Fetched page 162 with 1000 records.\n",
      "Fetched page 163 with 1000 records.\n",
      "Fetched page 164 with 1000 records.\n",
      "Fetched page 165 with 1000 records.\n",
      "Fetched page 166 with 1000 records.\n",
      "Fetched page 167 with 1000 records.\n",
      "Fetched page 168 with 1000 records.\n",
      "Fetched page 169 with 1000 records.\n",
      "Fetched page 170 with 1000 records.\n",
      "Fetched page 171 with 1000 records.\n",
      "Fetched page 172 with 1000 records.\n",
      "Fetched page 173 with 1000 records.\n",
      "Fetched page 174 with 1000 records.\n",
      "Fetched page 175 with 1000 records.\n",
      "Fetched page 176 with 1000 records.\n",
      "Fetched page 177 with 1000 records.\n",
      "Fetched page 178 with 1000 records.\n",
      "Fetched page 179 with 1000 records.\n",
      "Fetched page 180 with 1000 records.\n",
      "Fetched page 181 with 1000 records.\n",
      "Fetched page 182 with 1000 records.\n",
      "Fetched page 183 with 1000 records.\n",
      "Fetched page 184 with 1000 records.\n",
      "Fetched page 185 with 1000 records.\n",
      "Fetched page 186 with 1000 records.\n",
      "Fetched page 187 with 1000 records.\n",
      "Fetched page 188 with 1000 records.\n",
      "Fetched page 189 with 1000 records.\n",
      "Fetched page 190 with 1000 records.\n",
      "Fetched page 191 with 1000 records.\n",
      "Fetched page 192 with 1000 records.\n",
      "Fetched page 193 with 1000 records.\n",
      "Fetched page 194 with 1000 records.\n",
      "Fetched page 195 with 1000 records.\n",
      "Fetched page 196 with 1000 records.\n",
      "Fetched page 197 with 1000 records.\n",
      "Fetched page 198 with 1000 records.\n",
      "Fetched page 199 with 1000 records.\n",
      "Fetched page 200 with 1000 records.\n",
      "Fetched page 201 with 1000 records.\n",
      "Fetched page 202 with 1000 records.\n",
      "Fetched page 203 with 1000 records.\n",
      "Fetched page 204 with 1000 records.\n",
      "Fetched page 205 with 1000 records.\n",
      "Fetched page 206 with 1000 records.\n",
      "Fetched page 207 with 1000 records.\n",
      "Fetched page 208 with 1000 records.\n",
      "Fetched page 209 with 1000 records.\n",
      "Fetched page 210 with 1000 records.\n",
      "Fetched page 211 with 1000 records.\n",
      "Fetched page 212 with 1000 records.\n",
      "Fetched page 213 with 1000 records.\n",
      "Fetched page 214 with 1000 records.\n",
      "Fetched page 215 with 1000 records.\n",
      "Fetched page 216 with 1000 records.\n",
      "Fetched page 217 with 1000 records.\n",
      "Fetched page 218 with 1000 records.\n",
      "Fetched page 219 with 1000 records.\n",
      "Fetched page 220 with 1000 records.\n",
      "Fetched page 221 with 1000 records.\n",
      "Fetched page 222 with 1000 records.\n",
      "Fetched page 223 with 1000 records.\n",
      "Fetched page 224 with 1000 records.\n",
      "Fetched page 225 with 1000 records.\n",
      "Fetched page 226 with 1000 records.\n",
      "Fetched page 227 with 1000 records.\n",
      "Fetched page 228 with 1000 records.\n",
      "Fetched page 229 with 1000 records.\n",
      "Fetched page 230 with 1000 records.\n",
      "Fetched page 231 with 1000 records.\n",
      "Fetched page 232 with 1000 records.\n",
      "Fetched page 233 with 1000 records.\n",
      "Fetched page 234 with 1000 records.\n",
      "Fetched page 235 with 1000 records.\n",
      "Fetched page 236 with 1000 records.\n",
      "Fetched page 237 with 1000 records.\n",
      "Fetched page 238 with 1000 records.\n",
      "Fetched page 239 with 1000 records.\n",
      "Fetched page 240 with 1000 records.\n",
      "Fetched page 241 with 1000 records.\n",
      "Fetched page 242 with 1000 records.\n",
      "Fetched page 243 with 1000 records.\n",
      "Fetched page 244 with 1000 records.\n",
      "Fetched page 245 with 1000 records.\n",
      "Fetched page 246 with 1000 records.\n",
      "Fetched page 247 with 1000 records.\n",
      "Fetched page 248 with 1000 records.\n",
      "Fetched page 249 with 1000 records.\n",
      "Fetched page 250 with 1000 records.\n",
      "Fetched page 251 with 1000 records.\n",
      "Fetched page 252 with 1000 records.\n",
      "Fetched page 253 with 1000 records.\n",
      "Fetched page 254 with 1000 records.\n",
      "Fetched page 255 with 1000 records.\n",
      "Fetched page 256 with 1000 records.\n",
      "Fetched page 257 with 1000 records.\n",
      "Fetched page 258 with 1000 records.\n",
      "Fetched page 259 with 1000 records.\n",
      "Fetched page 260 with 1000 records.\n",
      "Fetched page 261 with 1000 records.\n",
      "Fetched page 262 with 1000 records.\n",
      "Fetched page 263 with 1000 records.\n",
      "Fetched page 264 with 1000 records.\n",
      "Fetched page 265 with 1000 records.\n",
      "Fetched page 266 with 1000 records.\n",
      "Fetched page 267 with 1000 records.\n",
      "Fetched page 268 with 1000 records.\n",
      "Fetched page 269 with 1000 records.\n",
      "Fetched page 270 with 1000 records.\n",
      "Fetched page 271 with 1000 records.\n",
      "Fetched page 272 with 1000 records.\n",
      "Fetched page 273 with 1000 records.\n",
      "Fetched page 274 with 1000 records.\n",
      "Fetched page 275 with 1000 records.\n",
      "Fetched page 276 with 1000 records.\n",
      "Fetched page 277 with 1000 records.\n",
      "Fetched page 278 with 1000 records.\n",
      "Fetched page 279 with 1000 records.\n",
      "Fetched page 280 with 1000 records.\n",
      "Fetched page 281 with 1000 records.\n",
      "Fetched page 282 with 1000 records.\n",
      "Fetched page 283 with 1000 records.\n",
      "Fetched page 284 with 1000 records.\n",
      "Fetched page 285 with 1000 records.\n",
      "Fetched page 286 with 1000 records.\n",
      "Fetched page 287 with 1000 records.\n",
      "Fetched page 288 with 1000 records.\n",
      "Fetched page 289 with 1000 records.\n",
      "Fetched page 290 with 1000 records.\n",
      "Fetched page 291 with 1000 records.\n",
      "Fetched page 292 with 1000 records.\n",
      "Fetched page 293 with 1000 records.\n",
      "Fetched page 294 with 1000 records.\n",
      "Fetched page 295 with 1000 records.\n",
      "Fetched page 296 with 1000 records.\n",
      "Fetched page 297 with 1000 records.\n",
      "Fetched page 298 with 1000 records.\n",
      "Fetched page 299 with 1000 records.\n",
      "Fetched page 300 with 1000 records.\n",
      "Fetched page 301 with 1000 records.\n",
      "Fetched page 302 with 1000 records.\n",
      "Fetched page 303 with 1000 records.\n",
      "Fetched page 304 with 1000 records.\n",
      "Fetched page 305 with 1000 records.\n",
      "Fetched page 306 with 1000 records.\n",
      "Fetched page 307 with 1000 records.\n",
      "Fetched page 308 with 1000 records.\n",
      "Fetched page 309 with 1000 records.\n",
      "Fetched page 310 with 1000 records.\n",
      "Fetched page 311 with 1000 records.\n",
      "Fetched page 312 with 1000 records.\n",
      "Fetched page 313 with 1000 records.\n",
      "Fetched page 314 with 1000 records.\n",
      "Fetched page 315 with 1000 records.\n",
      "Fetched page 316 with 1000 records.\n",
      "Fetched page 317 with 1000 records.\n",
      "Fetched page 318 with 1000 records.\n",
      "Fetched page 319 with 1000 records.\n",
      "Fetched page 320 with 1000 records.\n",
      "Fetched page 321 with 1000 records.\n",
      "Fetched page 322 with 1000 records.\n",
      "Fetched page 323 with 1000 records.\n",
      "Fetched page 324 with 1000 records.\n",
      "Fetched page 325 with 1000 records.\n",
      "Fetched page 326 with 1000 records.\n",
      "Fetched page 327 with 1000 records.\n",
      "Fetched page 328 with 1000 records.\n",
      "Fetched page 329 with 1000 records.\n",
      "Fetched page 330 with 1000 records.\n",
      "Fetched page 331 with 1000 records.\n",
      "Fetched page 332 with 1000 records.\n",
      "Fetched page 333 with 1000 records.\n",
      "Fetched page 334 with 1000 records.\n",
      "Fetched page 335 with 1000 records.\n",
      "Fetched page 336 with 1000 records.\n",
      "Fetched page 337 with 1000 records.\n",
      "Fetched page 338 with 1000 records.\n",
      "Fetched page 339 with 1000 records.\n",
      "Fetched page 340 with 1000 records.\n",
      "Fetched page 341 with 1000 records.\n",
      "Fetched page 342 with 1000 records.\n",
      "Fetched page 343 with 1000 records.\n",
      "Fetched page 344 with 1000 records.\n",
      "Fetched page 345 with 1000 records.\n",
      "Fetched page 346 with 1000 records.\n",
      "Fetched page 347 with 1000 records.\n",
      "Fetched page 348 with 1000 records.\n",
      "Fetched page 349 with 733 records.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 348733 entries, 0 to 348732\n",
      "Data columns (total 49 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   id                 348733 non-null  int64  \n",
      " 1   relid              348733 non-null  object \n",
      " 2   year               348733 non-null  int64  \n",
      " 3   active_year        348733 non-null  bool   \n",
      " 4   code_status        348733 non-null  object \n",
      " 5   type_of_violence   348733 non-null  int64  \n",
      " 6   conflict_dset_id   348733 non-null  object \n",
      " 7   conflict_new_id    348733 non-null  int64  \n",
      " 8   conflict_name      348733 non-null  object \n",
      " 9   dyad_dset_id       348733 non-null  object \n",
      " 10  dyad_new_id        348733 non-null  int64  \n",
      " 11  dyad_name          348733 non-null  object \n",
      " 12  side_a_dset_id     348733 non-null  object \n",
      " 13  side_a_new_id      348733 non-null  int64  \n",
      " 14  side_a             348733 non-null  object \n",
      " 15  side_b_dset_id     348733 non-null  object \n",
      " 16  side_b_new_id      348733 non-null  int64  \n",
      " 17  side_b             348733 non-null  object \n",
      " 18  number_of_sources  348733 non-null  int64  \n",
      " 19  source_article     348733 non-null  object \n",
      " 20  source_office      348733 non-null  object \n",
      " 21  source_date        348733 non-null  object \n",
      " 22  source_headline    348733 non-null  object \n",
      " 23  source_original    325336 non-null  object \n",
      " 24  where_prec         348733 non-null  int64  \n",
      " 25  where_coordinates  348733 non-null  object \n",
      " 26  where_description  340118 non-null  object \n",
      " 27  adm_1              330107 non-null  object \n",
      " 28  adm_2              280109 non-null  object \n",
      " 29  latitude           348733 non-null  float64\n",
      " 30  longitude          348733 non-null  float64\n",
      " 31  geom_wkt           348733 non-null  object \n",
      " 32  priogrid_gid       348733 non-null  int64  \n",
      " 33  country            348733 non-null  object \n",
      " 34  country_id         348733 non-null  int64  \n",
      " 35  region             348733 non-null  object \n",
      " 36  event_clarity      348733 non-null  int64  \n",
      " 37  date_prec          348733 non-null  int64  \n",
      " 38  date_start         348733 non-null  object \n",
      " 39  date_end           348733 non-null  object \n",
      " 40  deaths_a           348733 non-null  int64  \n",
      " 41  deaths_b           348733 non-null  int64  \n",
      " 42  deaths_civilians   348733 non-null  int64  \n",
      " 43  deaths_unknown     348733 non-null  int64  \n",
      " 44  best               348733 non-null  int64  \n",
      " 45  high               348733 non-null  int64  \n",
      " 46  low                348733 non-null  int64  \n",
      " 47  gwnoa              264962 non-null  object \n",
      " 48  gwnob              15910 non-null   object \n",
      "dtypes: bool(1), float64(2), int64(20), object(26)\n",
      "memory usage: 128.0+ MB\n",
      "1989-01-01T00:00:00\n",
      "2023-12-31T00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Actual filtering and storage of results\n",
    "\n",
    "# Getting the complete 24.1 official version as context and verification (without any filters)\n",
    "\n",
    "full_dataset = get_filtered_data(\n",
    "    version=version[\"latest_dataset\"]\n",
    ")\n",
    "\n",
    "\n",
    "full_dataset.info() # RangeIndex: 348,733 entries, 0 to 348,732 x 49 columns\n",
    "\n",
    "overall_min = full_dataset['date_end'].min()\n",
    "overall_max = full_dataset['date_end'].max()\n",
    "\n",
    "print(overall_min) # 1989-01-01 00:00:00\n",
    "print(overall_max) # 2023-12-31 00:00:00\n",
    "\n",
    "# Takes ~ 17 mins to fetch all records\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1af21a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "UCDP GED data from version 24.01.24.12 between 2024-01-01 and 2024-12-31\n",
      "Fetched page 1 with 1000 records.\n",
      "Fetched page 2 with 1000 records.\n",
      "Fetched page 3 with 1000 records.\n",
      "Fetched page 4 with 1000 records.\n",
      "Fetched page 5 with 1000 records.\n",
      "Fetched page 6 with 1000 records.\n",
      "Fetched page 7 with 1000 records.\n",
      "Fetched page 8 with 1000 records.\n",
      "Fetched page 9 with 1000 records.\n",
      "Fetched page 10 with 1000 records.\n",
      "Fetched page 11 with 1000 records.\n",
      "Fetched page 12 with 1000 records.\n",
      "Fetched page 13 with 1000 records.\n",
      "Fetched page 14 with 1000 records.\n",
      "Fetched page 15 with 1000 records.\n",
      "Fetched page 16 with 1000 records.\n",
      "Fetched page 17 with 1000 records.\n",
      "Fetched page 18 with 1000 records.\n",
      "Fetched page 19 with 1000 records.\n",
      "Fetched page 20 with 1000 records.\n",
      "Fetched page 21 with 1000 records.\n",
      "Fetched page 22 with 1000 records.\n",
      "Fetched page 23 with 1000 records.\n",
      "Fetched page 24 with 1000 records.\n",
      "Fetched page 25 with 1000 records.\n",
      "Fetched page 26 with 1000 records.\n",
      "Fetched page 27 with 1000 records.\n",
      "Fetched page 28 with 1000 records.\n",
      "Fetched page 29 with 1000 records.\n",
      "Fetched page 30 with 203 records.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 29203 entries, 0 to 29202\n",
      "Data columns (total 49 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 29203 non-null  int64  \n",
      " 1   relid              29203 non-null  object \n",
      " 2   year               29203 non-null  int64  \n",
      " 3   active_year        29203 non-null  bool   \n",
      " 4   code_status        29203 non-null  object \n",
      " 5   type_of_violence   29203 non-null  int64  \n",
      " 6   conflict_dset_id   29203 non-null  object \n",
      " 7   conflict_new_id    29203 non-null  int64  \n",
      " 8   conflict_name      29203 non-null  object \n",
      " 9   dyad_dset_id       29203 non-null  object \n",
      " 10  dyad_new_id        29203 non-null  int64  \n",
      " 11  dyad_name          29203 non-null  object \n",
      " 12  side_a_dset_id     29203 non-null  object \n",
      " 13  side_a_new_id      29203 non-null  int64  \n",
      " 14  side_a             29203 non-null  object \n",
      " 15  side_b_dset_id     29203 non-null  object \n",
      " 16  side_b_new_id      29203 non-null  int64  \n",
      " 17  side_b             29203 non-null  object \n",
      " 18  number_of_sources  29203 non-null  int64  \n",
      " 19  source_article     29203 non-null  object \n",
      " 20  source_office      29203 non-null  object \n",
      " 21  source_date        29203 non-null  object \n",
      " 22  source_headline    29203 non-null  object \n",
      " 23  source_original    27950 non-null  object \n",
      " 24  where_prec         29203 non-null  int64  \n",
      " 25  where_coordinates  29203 non-null  object \n",
      " 26  where_description  27764 non-null  object \n",
      " 27  adm_1              28435 non-null  object \n",
      " 28  adm_2              25904 non-null  object \n",
      " 29  latitude           29203 non-null  float64\n",
      " 30  longitude          29203 non-null  float64\n",
      " 31  geom_wkt           29203 non-null  object \n",
      " 32  priogrid_gid       29203 non-null  int64  \n",
      " 33  country            29203 non-null  object \n",
      " 34  country_id         29203 non-null  int64  \n",
      " 35  region             29203 non-null  object \n",
      " 36  event_clarity      29203 non-null  int64  \n",
      " 37  date_prec          29203 non-null  int64  \n",
      " 38  date_start         29203 non-null  object \n",
      " 39  date_end           29203 non-null  object \n",
      " 40  deaths_a           29203 non-null  int64  \n",
      " 41  deaths_b           29203 non-null  int64  \n",
      " 42  deaths_civilians   29203 non-null  int64  \n",
      " 43  deaths_unknown     29203 non-null  int64  \n",
      " 44  best               29203 non-null  int64  \n",
      " 45  high               29203 non-null  int64  \n",
      " 46  low                29203 non-null  int64  \n",
      " 47  gwnoa              21077 non-null  object \n",
      " 48  gwnob              10907 non-null  object \n",
      "dtypes: bool(1), float64(2), int64(20), object(26)\n",
      "memory usage: 10.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# FULL YEAR 2024, using candidate yearly dataset version\n",
    "\n",
    "full_2024 = get_filtered_data(\n",
    "    version=version[\"candidate_yearly_dataset\"], \n",
    "    start_date=\"2024-01-01\", # events on this day included\n",
    "    end_date=\"2024-12-31\"  # events on this day included\n",
    ")\n",
    "\n",
    "full_2024.info() # RangeIndex: 29203 entries, 0 to 29202 x 49 columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7519ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "UCDP GED data from version 24.1 between 2023-12-01 and latest\n",
      "Fetched page 1 with 778 records.\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 778 entries, 0 to 777\n",
      "Data columns (total 49 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   id                 778 non-null    int64  \n",
      " 1   relid              778 non-null    object \n",
      " 2   year               778 non-null    int64  \n",
      " 3   active_year        778 non-null    bool   \n",
      " 4   code_status        778 non-null    object \n",
      " 5   type_of_violence   778 non-null    int64  \n",
      " 6   conflict_dset_id   778 non-null    object \n",
      " 7   conflict_new_id    778 non-null    int64  \n",
      " 8   conflict_name      778 non-null    object \n",
      " 9   dyad_dset_id       778 non-null    object \n",
      " 10  dyad_new_id        778 non-null    int64  \n",
      " 11  dyad_name          778 non-null    object \n",
      " 12  side_a_dset_id     778 non-null    object \n",
      " 13  side_a_new_id      778 non-null    int64  \n",
      " 14  side_a             778 non-null    object \n",
      " 15  side_b_dset_id     778 non-null    object \n",
      " 16  side_b_new_id      778 non-null    int64  \n",
      " 17  side_b             778 non-null    object \n",
      " 18  number_of_sources  778 non-null    int64  \n",
      " 19  source_article     778 non-null    object \n",
      " 20  source_office      778 non-null    object \n",
      " 21  source_date        778 non-null    object \n",
      " 22  source_headline    778 non-null    object \n",
      " 23  source_original    746 non-null    object \n",
      " 24  where_prec         778 non-null    int64  \n",
      " 25  where_coordinates  778 non-null    object \n",
      " 26  where_description  733 non-null    object \n",
      " 27  adm_1              758 non-null    object \n",
      " 28  adm_2              726 non-null    object \n",
      " 29  latitude           778 non-null    float64\n",
      " 30  longitude          778 non-null    float64\n",
      " 31  geom_wkt           778 non-null    object \n",
      " 32  priogrid_gid       778 non-null    int64  \n",
      " 33  country            778 non-null    object \n",
      " 34  country_id         778 non-null    int64  \n",
      " 35  region             778 non-null    object \n",
      " 36  event_clarity      778 non-null    int64  \n",
      " 37  date_prec          778 non-null    int64  \n",
      " 38  date_start         778 non-null    object \n",
      " 39  date_end           778 non-null    object \n",
      " 40  deaths_a           778 non-null    int64  \n",
      " 41  deaths_b           778 non-null    int64  \n",
      " 42  deaths_civilians   778 non-null    int64  \n",
      " 43  deaths_unknown     778 non-null    int64  \n",
      " 44  best               778 non-null    int64  \n",
      " 45  high               778 non-null    int64  \n",
      " 46  low                778 non-null    int64  \n",
      " 47  gwnoa              396 non-null    object \n",
      " 48  gwnob              114 non-null    object \n",
      "dtypes: bool(1), float64(2), int64(20), object(26)\n",
      "memory usage: 292.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# SINCE DEC 1st, 2023, using latest official dataset version\n",
    "since_dec_2023 = get_filtered_data(\n",
    "    version=version[\"latest_dataset\"], \n",
    "    start_date=\"2023-12-01\" # events on this day included onwards until latest date available (which is 2023-12-31)\n",
    ")\n",
    "\n",
    "since_dec_2023.info() # RangeIndex: 778 entries, 0 to 777 x 49 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1d67136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 377936 entries, 0 to 377935\n",
      "Data columns (total 49 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   id                 377936 non-null  int64  \n",
      " 1   relid              377936 non-null  object \n",
      " 2   year               377936 non-null  int64  \n",
      " 3   active_year        377936 non-null  bool   \n",
      " 4   code_status        377936 non-null  object \n",
      " 5   type_of_violence   377936 non-null  int64  \n",
      " 6   conflict_dset_id   377936 non-null  object \n",
      " 7   conflict_new_id    377936 non-null  int64  \n",
      " 8   conflict_name      377936 non-null  object \n",
      " 9   dyad_dset_id       377936 non-null  object \n",
      " 10  dyad_new_id        377936 non-null  int64  \n",
      " 11  dyad_name          377936 non-null  object \n",
      " 12  side_a_dset_id     377936 non-null  object \n",
      " 13  side_a_new_id      377936 non-null  int64  \n",
      " 14  side_a             377936 non-null  object \n",
      " 15  side_b_dset_id     377936 non-null  object \n",
      " 16  side_b_new_id      377936 non-null  int64  \n",
      " 17  side_b             377936 non-null  object \n",
      " 18  number_of_sources  377936 non-null  int64  \n",
      " 19  source_article     377936 non-null  object \n",
      " 20  source_office      377936 non-null  object \n",
      " 21  source_date        377936 non-null  object \n",
      " 22  source_headline    377936 non-null  object \n",
      " 23  source_original    353286 non-null  object \n",
      " 24  where_prec         377936 non-null  int64  \n",
      " 25  where_coordinates  377936 non-null  object \n",
      " 26  where_description  367882 non-null  object \n",
      " 27  adm_1              358542 non-null  object \n",
      " 28  adm_2              306013 non-null  object \n",
      " 29  latitude           377936 non-null  float64\n",
      " 30  longitude          377936 non-null  float64\n",
      " 31  geom_wkt           377936 non-null  object \n",
      " 32  priogrid_gid       377936 non-null  int64  \n",
      " 33  country            377936 non-null  object \n",
      " 34  country_id         377936 non-null  int64  \n",
      " 35  region             377936 non-null  object \n",
      " 36  event_clarity      377936 non-null  int64  \n",
      " 37  date_prec          377936 non-null  int64  \n",
      " 38  date_start         377936 non-null  object \n",
      " 39  date_end           377936 non-null  object \n",
      " 40  deaths_a           377936 non-null  int64  \n",
      " 41  deaths_b           377936 non-null  int64  \n",
      " 42  deaths_civilians   377936 non-null  int64  \n",
      " 43  deaths_unknown     377936 non-null  int64  \n",
      " 44  best               377936 non-null  int64  \n",
      " 45  high               377936 non-null  int64  \n",
      " 46  low                377936 non-null  int64  \n",
      " 47  gwnoa              286039 non-null  object \n",
      " 48  gwnob              26817 non-null   object \n",
      "dtypes: bool(1), float64(2), int64(20), object(26)\n",
      "memory usage: 138.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# MERGING BOTH: FULL OFFICIAL DATASET + FULL 2024 \n",
    "\n",
    "combined_dfs = pd.concat([full_2024, full_dataset], ignore_index=True)\n",
    "combined_dfs.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b73750",
   "metadata": {},
   "source": [
    "#### 4.2 Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2984923f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adm_2\n",
       "Pokrovsk raion                     17849\n",
       "Deir al-Balah governorate           3929\n",
       "Bakhmut raion                       3603\n",
       "Gaza governorate                    3386\n",
       "Gaza ash Shamaliyah governorate     2851\n",
       "Name: best, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 1. What are the five deadliest municipalities (adm_2) overall in 2024?\n",
    "\n",
    "# Focus on variable:\n",
    "# best (integer): \"The best (most likely) estimate of total fatalities resulting from an event.\" (Högbladh, 2024; Sundberg et. al, 2013) \n",
    "\n",
    "full_2024.groupby('adm_2')['best'].sum().nlargest(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c175a316",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adm_2\n",
       "Deir al-Balah governorate          1801\n",
       "Gaza governorate                   1234\n",
       "Gaza ash Shamaliyah governorate     871\n",
       "El Fasher district                  797\n",
       "Rafah governorate                   729\n",
       "Name: deaths_civilians, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 2. What are the five deadliest municipalities (adm_2) just for civilians in 2024?\n",
    "\n",
    "# Focus on variable:\n",
    "# deaths_civilians (integer):\"The best estimate of dead civilians in the event.  For non-state or state-based events, this is the number of collateral damage resulting in fighting between side a and side integer b. For one-sided violence, it is the number of civilians killed by side a.\" (Högbladh, 2024; Sundberg et. al, 2013) \n",
    "\n",
    "full_2024.groupby('adm_2')['deaths_civilians'].sum().nlargest(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e8dea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPTION 1: The province with the largest increase in overall violence (in number of unique events) since December 2023 is:\n",
      "adm_1\n",
      "Gaza Strip    65\n",
      "Name: id, dtype: int64\n",
      "OPTION 1: The province with the largest decrease in overall violence (in number of unique events) since December 2023 is:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "adm_1\n",
       "Adamawa state    1\n",
       "Name: id, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# For Q3 & Q4: Given the instructions and the datasets consulted, I interpret different possibilities to answer them,\n",
    "\n",
    "\n",
    "# Option 1 -> I can only find the highest and lowest count of unique events in DEC 2023 (strictly using just the official latest dataset and the defined date filter)\n",
    "\n",
    "# 3. Which province (adm_1) has seen the largest increase in overall violence since December 2023?\n",
    "# id (integer) = \"A unique numeric ID identifying each event.\" (Högbladh, 2024; Sundberg et. al, 2013) \n",
    "print(\"OPTION 1: The province with the largest increase in overall violence (in number of unique events) since December 2023 is:\")\n",
    "print(since_dec_2023.groupby('adm_1')['id'].count().nlargest(1))\n",
    "\n",
    "#4. Which province (adm_1) has seen the largest decrease in overall violence since December 2023?\n",
    "print(\"OPTION 1: The province with the largest decrease in overall violence (in number of unique events) since December 2023 is:\")\n",
    "since_dec_2023.groupby('adm_1')['id'].count().nsmallest(1) # Of course, there must be at least 1 event (lowest count), several have just 1 event \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c35cde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPTION 2: Largest increase since DEC 2023 (province level): Kursk oblast (498 more events)\n",
      "OPTION 2: Largest decrease since DEC 2023 (province level): Rif Dimashq governorate (-17401 fewer events)\n"
     ]
    }
   ],
   "source": [
    "# Option 2 -> using merged df and comparing\n",
    "\n",
    "combined_dfs['date_end'] = pd.to_datetime(combined_dfs['date_end']) # just to confirm the data type\n",
    "\n",
    "# Date splits\n",
    "before = combined_dfs[combined_dfs['date_end'] < '2023-12-01'] # since DEC 2023\n",
    "after = combined_dfs[combined_dfs['date_end'] >= '2023-12-01'] # onwards\n",
    "\n",
    "change = (\n",
    "    after['adm_1'].value_counts() - \n",
    "    before['adm_1'].value_counts()).fillna(0) # comparing province series of unique events, gives positive and negative changes\n",
    "\n",
    "print(f\"OPTION 2: Largest increase since DEC 2023 (province level): {change.idxmax()} ({int(change.max())} more events)\") # printing index label for largest value (province) and actual count (largest)\n",
    "print(f\"OPTION 2: Largest decrease since DEC 2023 (province level): {change.idxmin()} ({int(change.min())} fewer events)\") # printing index label for lowest value (province) and actual count (min)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c5073c",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38abb83",
   "metadata": {},
   "source": [
    "Davies, Shawn, Garoun Engström, Therese Pettersson & Magnus Öberg (2024). Organized violence 1989-2023, and the prevalence of organized crime groups. Journal of Peace Research 61(4).\n",
    "\n",
    "Goodwin, M. (2024, April 9). What Is an API (Application Programming Interface)? IBM. https://www.ibm.com/think/topics/api\n",
    "\n",
    "Högbladh, Stina. (2024). “UCDP GED Codebook version 24.1”, Department of Peace and Conflict Research, Uppsala University\n",
    "\n",
    "IBM Technology (Director). (2020, October 23). What is a REST API? [Video recording]. https://www.youtube.com/watch?v=lsMQRaeKNDk\n",
    "\n",
    "JSON. (n.d.). Retrieved April 7, 2025, from https://www.json.org/json-en.html\n",
    "\n",
    "Sundberg, Ralph and Erik Melander (2013) Introducing the UCDP Georeferenced Event Dataset. Journal of Peace Research 50(4). 523-532\n",
    "\n",
    "UCDP Application Programming Interface (API). (n.d.). Retrieved April 7, 2025, from https://ucdp.uu.se/apidocs/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1af11c62",
   "metadata": {},
   "source": [
    "________________"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
