{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66c0df0e",
   "metadata": {},
   "source": [
    "# **Database Monitoring Script - Cocaine Seizures 2025 (Google Sheets)**\n",
    "#### InSight Crime - MAD Unit \n",
    "June, 2025\n",
    "\n",
    "---------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d6e936",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac164b48",
   "metadata": {},
   "source": [
    "#### Version Control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7255ac",
   "metadata": {},
   "source": [
    "The project is created within a single GitHub repository ([FelipeVillota/db-check-cocaine-seizures](https://github.com/FelipeVillota/db-check-cocaine-seizures)). I keep the repository `private` with the possibility to give access to the online repo at any time. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad16f5b0",
   "metadata": {},
   "source": [
    "#### Reproducible Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1112678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT\n",
    "# To create venv\n",
    "# python -m venv venv-db-watch\n",
    "\n",
    "# To activate environment, run in Terminal:\n",
    "# # (optional, temporary auth) \n",
    "# Set-ExecutionPolicy -Scope Process -ExecutionPolicy Bypass \n",
    "# venv-db-watch\\Scripts\\activate\n",
    "\n",
    "# Then select respective kernel --> also install ipykernel package to connect to kernel\n",
    "\n",
    "# Update list master list\n",
    "# pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "898046a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\Desktop\\ic\\db-check-cocaine-seizures\\venv-db-watch\\Scripts\\python.exe\n"
     ]
    }
   ],
   "source": [
    "# Checking venv-db-watch works\n",
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802dc17a",
   "metadata": {},
   "source": [
    "#### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03411ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install --upgrade google-api-python-client google-auth-httplib2 google-auth-oauthlib pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "735fe917",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from google.oauth2 import service_account\n",
    "from googleapiclient.discovery import build\n",
    "import gspread\n",
    "from google.oauth2.service_account import Credentials\n",
    "from gspread_formatting import format_cell_ranges, CellFormat, Color\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "\n",
    "# pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db308e65",
   "metadata": {},
   "source": [
    "### Accessing the API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d60b66",
   "metadata": {},
   "source": [
    "This creates a modular client (frontend) call that is able to extract the desired subset of data from the API server (backend); -and, make it easily reusable for future queries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7295a8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure Google Drive API\n",
    "\n",
    "# Path to your service account key file\n",
    "SERVICE_ACCOUNT_FILE = 'C:/Users/USER/Desktop/ic/llavero/summer-sector-439022-v6-2eafffbbfb90.json' # Update with the actual path or team credentials file\n",
    "\n",
    "# Original (latest version) Google Sheet ID\n",
    "ORIGINAL_SPREADSHEET_ID =  '1t61MafCmnRe2QN082Bk1V0IxBSIW8UUqH1g5mULgb2o' \n",
    "\n",
    "# Test Google Sheet ID\n",
    "TEST_SPREADSHEET_ID = '1tERxVx_Ay4WDOXIvEXezFpiBZKBPUJNuZQl8NUpHt1g' \n",
    " \n",
    "# Define the sheet tab or range to read\n",
    "RANGE_NAME = '2025'\n",
    "\n",
    "# Define scopes for Google Sheets and Drive API\n",
    "SCOPES = ['https://www.googleapis.com/auth/spreadsheets', \n",
    "          'https://www.googleapis.com/auth/drive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0b26502",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate and build both Sheets and Drive services\n",
    "creds = service_account.Credentials.from_service_account_file(\n",
    "    SERVICE_ACCOUNT_FILE, scopes=SCOPES)\n",
    "sheet_service = build('sheets', 'v4', credentials=creds)\n",
    "drive_service = build('drive', 'v3', credentials=creds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093f930e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Last modified by: Error\n",
      "‚è∞ Last modified at: Error: <HttpError 403 when requesting https://www.googleapis.com/drive/v3/files/1tERxVx_Ay4WDOXIvEXezFpiBZKBPUJNuZQl8NUpHt1g/revisions?fields=revisions%28modifiedTime%2ClastModifyingUser%29&alt=json returned \"The user does not have sufficient permissions to read revisions for file 1tERxVx_Ay4WDOXIvEXezFpiBZKBPUJNuZQl8NUpHt1g.\". Details: \"[{'message': 'The user does not have sufficient permissions to read revisions for file 1tERxVx_Ay4WDOXIvEXezFpiBZKBPUJNuZQl8NUpHt1g.', 'domain': 'global', 'reason': 'insufficientFilePermissions'}]\">\n"
     ]
    }
   ],
   "source": [
    "# Verify last modifying user and time of the original spreadsheet. This information is related to the file itself, not to specific content (sheets, cells, rows)\n",
    "\n",
    "from googleapiclient.discovery import build\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "def get_last_modifying_user(drive_service, file_id):\n",
    "    try:\n",
    "        # Get revisions (only the last one)\n",
    "        revisions = drive_service.revisions().list(\n",
    "            fileId=file_id,\n",
    "            fields=\"revisions(modifiedTime,lastModifyingUser)\"\n",
    "        ).execute().get('revisions', [])\n",
    "        \n",
    "        if not revisions:\n",
    "            return \"No revisions found.\"\n",
    "        \n",
    "        last_revision = revisions[-1]  # Most recent revision\n",
    "        user_info = last_revision.get('lastModifyingUser', {})\n",
    "        display_name = user_info.get('displayName', 'Unknown')\n",
    "        email = user_info.get('emailAddress', 'Unknown')\n",
    "        modified_time = last_revision.get('modifiedTime', 'Unknown')\n",
    "        \n",
    "        # Convert to readable datetime\n",
    "        if modified_time != 'Unknown':\n",
    "            dt = datetime.strptime(modified_time, \"%Y-%m-%dT%H:%M:%S.%fZ\")\n",
    "            dt = dt.replace(tzinfo=pytz.UTC)\n",
    "            modified_time = dt.strftime(\"%Y-%m-%d %H:%M:%S (UTC)\")\n",
    "        \n",
    "        return {\n",
    "            \"user_display_name\": display_name,\n",
    "            \"user_email\": email,\n",
    "            \"modified_time\": modified_time\n",
    "        }\n",
    "    \n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# Usage\n",
    "last_modifier = get_last_modifying_user(drive_service, TEST_SPREADSHEET_ID)\n",
    "print(f\"üîÑ Last modified by: {last_modifier['user_display_name']} ({last_modifier['user_email']})\")\n",
    "print(f\"‚è∞ Last modified at: {last_modifier['modified_time']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb5b450",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a28d2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Type   Time unit        Date Date 2  Year Month Day Duration  \\\n",
      "0  Seizure  Individual  2025-03-24         2025     3  24            \n",
      "1  Seizure  Individual  2025-03-23         2025     3  23            \n",
      "2  Seizure  Individual  2025-03-22         2025     3  22            \n",
      "3  Seizure  Individual  2025-03-22         2025     3  22            \n",
      "4  Seizure  Individual  2025-03-19         2025     3  19            \n",
      "\n",
      "                       Type Drugs Quantity  ... Destition - department.state  \\\n",
      "0                         Cocaine       10  ...                                \n",
      "1                         Cocaine      2.5  ...                                \n",
      "2                         Cocaine     2619  ...                                \n",
      "3  Other (explain in Description)     1240  ...                                \n",
      "4                         Cocaine    16.05  ...                                \n",
      "\n",
      "  Destition - Municipality/Port Destition 2 - Country  \\\n",
      "0                                                       \n",
      "1                        Madrid                         \n",
      "2                                                       \n",
      "3                                                       \n",
      "4                                                       \n",
      "\n",
      "  Destition 2 - Municipality/Port  \\\n",
      "0                                   \n",
      "1                                   \n",
      "2                                   \n",
      "3                                   \n",
      "4                                   \n",
      "\n",
      "                                         Description Criminal group #1  \\\n",
      "0  Spanish citizen, coming from Lisbon , was stop...                     \n",
      "1  Dominican-Spanish flying to Madrid and was arr...                     \n",
      "2  2,619 kilos was found buried on a small island...                     \n",
      "3  1,240 kilos of liquid cocaine hidden in roofin...                     \n",
      "4  16 packages totaling 35.4 pounds (16.05 kg) of...                     \n",
      "\n",
      "  Criminal group #2 Criminal group #3  \\\n",
      "0                                       \n",
      "1                                       \n",
      "2                                       \n",
      "3                                       \n",
      "4                                       \n",
      "\n",
      "                                         Source link Project interested  \n",
      "0  https://www.lanazione.it/firenze/cronaca/cocai...               None  \n",
      "1  https://rccnoticias.com.do/operativo-en-el-ail...               None  \n",
      "2  https://rci.fm/deuxiles/infos/Faits-divers/Ven...               None  \n",
      "3  https://rci.fm/deuxiles/infos/Faits-divers/Ven...               None  \n",
      "4  https://eldiariony.com/2025/03/23/cbp-incauta-...               None  \n",
      "\n",
      "[5 rows x 41 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    " \n",
    "# Call the Sheets API to read data\n",
    "sheet = sheet_service.spreadsheets()\n",
    "result = sheet.values().get(spreadsheetId=TEST_SPREADSHEET_ID, range=RANGE_NAME).execute()\n",
    "values = result.get('values', [])\n",
    "\n",
    "# Convert to DataFrame for easier manipulation\n",
    "df = pd.DataFrame(values[1:], columns=values[0])\n",
    "print(df.head()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b73750",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3ced22bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Converted empty strings/whitespace to NA values\n"
     ]
    }
   ],
   "source": [
    "# Handle Missing/Invalid Values\n",
    " \n",
    "df = df.replace('', pd.NA)  # Convert empty strings to NA\n",
    "df = df.replace(r'^\\s*$', pd.NA, regex=True)  # Convert whitespace to NA\n",
    "print(\"‚úì Converted empty strings/whitespace to NA values\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "286ff908",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîΩ Type: ['Crop Eradication', 'Total Crop Cultivation Estimate', 'Price', 'Total Production Estimate', 'Other (explain in Description)', 'Seizure']\n",
      "üîΩ Time unit: ['Multi-Year', 'Multi-Month', 'Month', 'Other (explain in Description)', 'Individual', 'Year']\n",
      "üîΩ Type Drugs: ['Coca Crops', 'All/Unspecified/Multiple', 'Cocaine', 'Other (explain in Description)', 'Cocaine - Crack', 'Cocaine Base']\n",
      "üîΩ Weight unit: ['Percent', 'Other currency (say which in Description)', 'Hectare', 'Euro', 'Plant', 'USD', 'Other (explain in Description)', 'Pounds (lbs)', 'Kilogram', 'Pounds (¬£)', 'Package']\n",
      "üîΩ Modus Operandi/place of seizure: ['River vessel', 'Container', 'Maritime vessel', 'Land', 'Air']\n",
      "üîΩ Region: ['Global', 'Central America', 'Asia', 'Europe', 'Oceania', 'South America', 'Caribbean', 'North America', 'Africa']\n",
      "üîΩ Origin country: ['Peru', 'Bolivia', '\"\"', 'Colombia']\n",
      "üîΩ Transit 1/Region: ['Global', 'Central America', 'Asia', 'Europe', 'Oceania', 'South America', 'Caribbean', 'North America', 'Africa']\n",
      "üîΩ Transit 2/ region: ['Global', 'Central America', 'Asia', 'Europe', 'Oceania', 'South America', 'Caribbean', 'North America', 'Africa']\n",
      "üîΩ Destition - Region: ['Central America', 'Asia', 'Europe', 'South America', 'Caribbean', 'North America', 'Australia', 'Africa']\n",
      "üîΩ Project interested: ['Cocaine Pipeline', 'El PACCTO 2.0', 'MAD', 'Dutch']\n"
     ]
    }
   ],
   "source": [
    "# Indentify Existing Dropdowns\n",
    " \n",
    "def get_sheet_dropdowns(spreadsheet_id, sheet_name, creds):\n",
    "    service = build('sheets', 'v4', credentials=creds)\n",
    "    sheet_metadata = service.spreadsheets().get(\n",
    "        spreadsheetId=spreadsheet_id,\n",
    "        ranges=[sheet_name],\n",
    "        includeGridData=True\n",
    "    ).execute()\n",
    "\n",
    "    dropdowns_by_column = {}\n",
    "\n",
    "    for sheet in sheet_metadata['sheets']:\n",
    "        if sheet['properties']['title'] != sheet_name:\n",
    "            continue\n",
    "\n",
    "        col_dropdowns = {}\n",
    "        rows = sheet['data'][0]['rowData']\n",
    "        header_row = rows[0]['values']\n",
    "        col_names = [cell.get('formattedValue', f\"Column_{i}\") for i, cell in enumerate(header_row)]\n",
    "\n",
    "        for col_idx, col_name in enumerate(col_names):\n",
    "            dropdowns_in_col = set()\n",
    "            for row in rows[1:]:  # Skip header\n",
    "                cell = row['values'][col_idx]\n",
    "                if 'dataValidation' in cell:\n",
    "                    dv = cell['dataValidation']\n",
    "                    if dv['condition']['type'] == 'ONE_OF_LIST':\n",
    "                        values = [v['userEnteredValue'] for v in dv['condition']['values']]\n",
    "                        dropdowns_in_col.update(values)\n",
    "            if dropdowns_in_col:\n",
    "                col_dropdowns[col_name] = list(dropdowns_in_col)\n",
    "\n",
    "        dropdowns_by_column.update(col_dropdowns)\n",
    "\n",
    "    return dropdowns_by_column\n",
    "\n",
    "dropdown_options = get_sheet_dropdowns(TEST_SPREADSHEET_ID, '2025', creds)\n",
    "\n",
    "# Print results\n",
    "for col, options in dropdown_options.items():\n",
    "    print(f\"üîΩ {col}: {options}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba68aa90",
   "metadata": {},
   "source": [
    "## Monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3719617",
   "metadata": {},
   "source": [
    "##### Summary Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d07f2e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataframe_summary(df):\n",
    "    # --- General DataFrame Info ---\n",
    "    general_info = {\n",
    "        \"Shape\": f\"{df.shape[0]} rows √ó {df.shape[1]} cols\",\n",
    "        \"Memory Usage\": f\"{df.memory_usage(deep=True).sum() / (1024 ** 2):.2f} MB\",\n",
    "        \"Columns with NA\": f\"{df.isna().any().sum()} / {len(df.columns)}\",\n",
    "        \"Duplicate Rows\": f\"{df.duplicated().sum()} ({(df.duplicated().mean() * 100):.1f}%)\",\n",
    "        \"Numeric Columns\": f\"{df.select_dtypes(include='number').shape[1]}\",\n",
    "        \"Categorical Columns\": f\"{df.select_dtypes(include=['object', 'category']).shape[1]}\",\n",
    "        \"Datetime Columns\": f\"{df.select_dtypes(include='datetime').shape[1]}\"\n",
    "    }\n",
    "\n",
    "  # --- Compute dropdown options per column ---\n",
    "    dropdown_options_dict = {\n",
    "        col: dropdown_options.get(col, [])\n",
    "        for col in df.columns\n",
    "    }\n",
    "    # --- Column-Level Stats ---\n",
    "    column_stats = pd.DataFrame({\n",
    "        'Variable': df.columns,\n",
    "        'Dtype': df.dtypes.values,\n",
    "        'Unique_Count': df.nunique().values,\n",
    "        'NA_Count': df.isna().sum().values,\n",
    "        'NA_Percentage': (df.isna().mean() * 100).round(1).values,\n",
    "        'Duplicate_Count': df.apply(lambda col: col.duplicated(keep=False).sum()).values,\n",
    "        'Duplicate_Percentage': (df.apply(lambda col: col.duplicated(keep=False).mean()) * 100).round(1).values,\n",
    "        'Unique_Values': df.apply(lambda x: x.drop_duplicates().tolist()).values,\n",
    "        'Dropdown_Options': [dropdown_options_dict[col] for col in df.columns],\n",
    "        'Dropdown_Option_Count': [len(dropdown_options_dict[col]) for col in df.columns]\n",
    "    }).sort_values('Unique_Count', ascending=False)\n",
    "\n",
    "\n",
    "    # Format percentages\n",
    "    column_stats['NA_Percentage'] = column_stats['NA_Percentage'].astype(str) + '%'\n",
    "    column_stats['Duplicate_Percentage'] = column_stats['Duplicate_Percentage'].astype(str) + '%'\n",
    "\n",
    "    return general_info, column_stats\n",
    "\n",
    "# Run the summary\n",
    "general_info, column_stats = get_dataframe_summary(df)\n",
    "\n",
    "# Print General Info\n",
    "print(\"=== GENERAL DATAFRAME INFO ===\")\n",
    "for key, value in general_info.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "# Display Column Stats (including dropdown options)\n",
    "print(\"\\n=== COLUMN-LEVEL STATISTICS ===\")\n",
    "display(column_stats)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bb3843",
   "metadata": {},
   "source": [
    "##### Missing Data Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35660cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "missing_values = df.isnull().sum()\n",
    "print(f\"Missing values per column:\\n{missing_values}\\n\")\n",
    "\n",
    "# Visualization 1: Bar Chart\n",
    "plt.figure(figsize=(12, 5))\n",
    "ax = missing_values.plot(kind='bar', color=\"#000000\", width=0.6)\n",
    "ax.grid(False)\n",
    "for i in ax.patches:\n",
    "    ax.text(i.get_x() + i.get_width()/2, i.get_height()+1, \n",
    "            f'{int(i.get_height())}', \n",
    "            ha='center', fontsize=10)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "sns.despine()\n",
    "plt.title(\"Missing Values per Column\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Visualization 2: Missingno Matrix\n",
    "msno.matrix(\n",
    "    df,\n",
    "    figsize=(20, 8),\n",
    "    color=(0.1, 0.1, 0.1),\n",
    "    sparkline=False,\n",
    "    fontsize=12,\n",
    "    labels=True\n",
    ")\n",
    "plt.title(\"Missing Value Patterns\", fontsize=16, pad=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359a6f4a",
   "metadata": {},
   "source": [
    "##### Key Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75caf461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Identify mismatches between 'Weight unit' and 'Quantity' vs 'seizure_kgs'\n",
    "df['kg_unit_mismatch'] = (\n",
    "    (df['Weight unit'].str.lower() == 'Kilogram') &\n",
    "    (df['Quantity'] != df['seizure_kgs'])\n",
    ")\n",
    "\n",
    "# 2. Count of mismatches by weight unit\n",
    "unit_mismatch_counts = df[df['kg_unit_mismatch']].groupby('Weight unit').size().reset_index(name='count')\n",
    "\n",
    "# 3. Plot mismatches\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(data=unit_mismatch_counts, x='Weight unit', y='count', palette='Reds')\n",
    "plt.title(\"Mismatches Between Quantity and Seizure_kgs by Weight Unit\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b3886f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Boxplot with grey boxes\n",
    "sns.boxplot(data=df, x='Type Drugs', y='seizure_kgs', color='grey')\n",
    "\n",
    "# Log scale on y-axis\n",
    "plt.yscale('log')\n",
    "\n",
    "# Red horizontal line at y=1 (which is 10^0)\n",
    "plt.axhline(y=1, color='red', linestyle='--', linewidth=1.5)\n",
    "\n",
    "plt.title(\"Log-Scale Seizure_kgs Distribution by Drug Type\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078b376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert and clean seizure data\n",
    "df['seizure_kgs'] = pd.to_numeric(df['seizure_kgs'], errors='coerce')\n",
    "\n",
    "# Create pivot tables with matching structure\n",
    "pivot_data = df.groupby(['Year', 'Month']).agg(\n",
    "    seizure_kg=('seizure_kgs', 'sum'),\n",
    "    event_count=('seizure_kgs', 'count')\n",
    ").unstack(level=0)\n",
    "\n",
    "# Extract components\n",
    "seizure_kg = pivot_data['seizure_kg']\n",
    "event_counts = pivot_data['event_count']\n",
    "\n",
    "# Fill NaN values with 0 if appropriate, or use mask\n",
    "seizure_kg_filled = seizure_kg.fillna(0)\n",
    "\n",
    "# Plot combined heatmap\n",
    "plt.figure(figsize=(12,6))\n",
    "ax = sns.heatmap(\n",
    "    seizure_kg_filled.sort_index(ascending=False),\n",
    "    cmap=\"Greys\",\n",
    "    annot=event_counts.sort_index(ascending=False),\n",
    "    fmt='g',\n",
    "    cbar_kws={'label': 'Total Seizure (kg)'},\n",
    "    linewidths=0.5,  # Adds grid lines between cells\n",
    "    linecolor='lightgray'  # Color for grid lines\n",
    ")\n",
    "\n",
    "# Title and labels\n",
    "plt.title(\"Monthly Seizures by Year\\n(Event Counts shown as numbers, Quantity shown by shading)\")\n",
    "plt.ylabel(\"Month\")\n",
    "plt.xlabel(\"Year\")\n",
    "\n",
    "# Rotate year labels if needed\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c8bc11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_parallel_sets(df): \n",
    "    # Define the column names\n",
    "    columns = ['Origin country', 'Transit 1/country', 'Transit 2/ country',\n",
    "               'Destition - Country', 'Destition 2 - Country']\n",
    "    \n",
    "    # Copy and fill missing values\n",
    "    df = df[columns].copy()\n",
    "    df[columns[1]] = df[columns[1]].fillna('No Transit')\n",
    "    df[columns[2]] = df[columns[2]].fillna('No Transit')\n",
    "    df[columns[4]] = df[columns[4]].fillna('No Destination 2')\n",
    "    \n",
    "    # Filter incomplete rows\n",
    "    df.dropna(subset=[columns[0], columns[3]], inplace=True)\n",
    "    if df.empty:\n",
    "        print(\"Warning: No data with both origin and destination information\")\n",
    "        return\n",
    "    \n",
    "    # Count path frequencies\n",
    "    path_counts = df.groupby(columns).size().reset_index(name='count')\n",
    "    \n",
    "    # Prepare the plot\n",
    "    plt.figure(figsize=(20, 12))\n",
    "\n",
    "    # Map each category to a y-position (starting at 1)\n",
    "    categories = {}\n",
    "    for col in columns:\n",
    "        values = df[col].unique()\n",
    "        sorted_vals = sorted([v for v in values if \"No\" not in v]) + sorted([v for v in values if \"No\" in v])\n",
    "        categories[col] = {val: idx + 1 for idx, val in enumerate(sorted_vals)}\n",
    "    \n",
    "    # Plot each path\n",
    "    for _, row in path_counts.iterrows():\n",
    "        y_values = [categories[col][row[col]] for col in columns]\n",
    "        plt.plot(range(len(columns)), y_values, linewidth=row['count'] * 2, alpha=0.6)\n",
    "\n",
    "    # X-axis: step names\n",
    "    plt.xticks(range(len(columns)), ['Origin', 'Transit 1', 'Transit 2', 'Destination 1', 'Destination 2'], fontsize=12)\n",
    "    \n",
    "    # Y-axis: remove default numbers\n",
    "    plt.yticks([])\n",
    "    \n",
    "    # Add node labels\n",
    "    for i, col in enumerate(columns):\n",
    "        for val, y in categories[col].items():\n",
    "            plt.text(i, y, val, ha='center', va='center',\n",
    "                     bbox=dict(facecolor='white', alpha=0.8, edgecolor='none'), fontsize=10)\n",
    "    \n",
    "    # Final touches\n",
    "    plt.title(\"Drug Trafficking Routes: Origin ‚Üí Transit 1 ‚Üí Transit 2 ‚Üí Destination 1 ‚Üí Destination 2\", \n",
    "              fontsize=16, pad=20)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Usage:\n",
    "plot_parallel_sets(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab039f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Group counts\n",
    "mo = df['Modus Operandi/place of seizure'].value_counts().sort_index()\n",
    "sub_mo = df.groupby('Modus Operandi/place of seizure')['Sub MO'].count().reindex(mo.index)\n",
    "\n",
    "# Plot\n",
    "labels = mo.index\n",
    "x = np.arange(len(labels))\n",
    "w = 0.35\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "b1 = ax.bar(x - w/2, mo, w, label='MO Count', color=\"#000000\")\n",
    "b2 = ax.bar(x + w/2, sub_mo, w, label='Sub MO Count', color=\"#FA0707\")\n",
    "\n",
    "# Label bars\n",
    "for bars in [b1, b2]:\n",
    "    for bar in bars:\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height()/2,\n",
    "                str(int(bar.get_height())), ha='center', va='center', color='white', fontsize=9)\n",
    "\n",
    "# Style\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(labels, rotation=45, ha='right')\n",
    "ax.set_title('Modus Operandi and Sub MO Counts', fontsize=14)\n",
    "ax.legend()\n",
    "ax.set_ylabel('Count')\n",
    "plt.tight_layout()\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.3)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6983008a",
   "metadata": {},
   "source": [
    "## Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119eabd1",
   "metadata": {},
   "source": [
    "#### Event Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0ca738",
   "metadata": {},
   "source": [
    "Variables: _Type, Time unit, Date, Date 2, Year, Month, Day, Duration, Description, Source link, Project interested_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f983db34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Date must not be empty\n",
    "def validate_dates(df, date_column='Date'):\n",
    "    if date_column not in df.columns:\n",
    "        print(f\"‚ùå Column '{date_column}' not found\")\n",
    "        return\n",
    "    \n",
    "    # Check for empty dates\n",
    "    empty_dates = df[df[date_column].isna()]\n",
    "    \n",
    "    if not empty_dates.empty:\n",
    "        print(f\"‚ùå Found {len(empty_dates)} rows with empty '{date_column}' dates:\")\n",
    "        print(empty_dates)\n",
    "    else:\n",
    "        print(f\"‚úÖ All '{date_column}' dates are filled\")\n",
    "\n",
    "\n",
    "validate_dates(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9557a5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why is there Duration if there is no Date 2?  \n",
    "def validate_duration(df, date_column='Date', date2_column='Date 2', duration_column='Duration'):\n",
    "    if date_column not in df.columns or date2_column not in df.columns or duration_column not in df.columns:\n",
    "        print(f\"‚ùå One or more columns '{date_column}', '{date2_column}', or '{duration_column}' not found\")\n",
    "        return\n",
    "    \n",
    "    # Check for rows where Date 2 is empty but Duration is filled\n",
    "    invalid_rows = df[(df[date2_column].isna()) & (df[duration_column].notna())]\n",
    "    \n",
    "    if not invalid_rows.empty:\n",
    "        print(f\"‚ùå Found {len(invalid_rows)} rows with '{duration_column}' filled but '{date2_column}' empty:\")\n",
    "        print(invalid_rows)\n",
    "    else:\n",
    "        print(f\"‚úÖ All '{duration_column}' values are valid with respect to '{date2_column}'\")\n",
    "\n",
    "validate_duration(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326943dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if Date 2 is filed, then Time unit is not Individual\n",
    "def validate_time_unit(df, date2_column='Date 2', time_unit_column='Time unit'):\n",
    "    if date2_column not in df.columns or time_unit_column not in df.columns:\n",
    "        print(f\"‚ùå One or more columns '{date2_column}' or '{time_unit_column}' not found\")\n",
    "        return\n",
    "    \n",
    "    # Check for rows where Date 2 is filled but Time unit is 'Individual'\n",
    "    invalid_rows = df[(df[date2_column].notna()) & (df[time_unit_column] == 'Individual')]\n",
    "    \n",
    "    if not invalid_rows.empty:\n",
    "        print(f\"‚ùå Found {len(invalid_rows)} rows with '{time_unit_column}' as 'Individual' but '{date2_column}' filled:\")\n",
    "        print(invalid_rows)\n",
    "    else:\n",
    "        print(f\"‚úÖ All '{time_unit_column}' values are valid with respect to '{date2_column}'\") \n",
    "\n",
    "validate_time_unit(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fb1e49",
   "metadata": {},
   "source": [
    "## Direct Edits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ea2385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update a column name directly in Google Sheets\n",
    "def update_column_name(old_name, new_name):\n",
    "    # Get headers\n",
    "    headers = sheet.values().get(spreadsheetId=SPREADSHEET_ID, range='2025!1:1').execute()['values'][0]\n",
    "    \n",
    "    # Find and update column\n",
    "    if old_name in headers:\n",
    "        col_index = headers.index(old_name)\n",
    "        col_letter = chr(65 + col_index)  # Convert to A, B, C...\n",
    "        \n",
    "        # Update in sheet\n",
    "        sheet.values().update(\n",
    "            spreadsheetId=SPREADSHEET_ID,\n",
    "            range=f'2025!{col_letter}1',\n",
    "            valueInputOption='RAW',\n",
    "            body={'values': [[new_name]]}\n",
    "        ).execute()\n",
    "        \n",
    "        print(f\"‚úÖ '{old_name}' ‚Üí '{new_name}'\")\n",
    "    else:\n",
    "        print(f\"‚ùå '{old_name}' not found\")\n",
    "\n",
    "# Function usage\n",
    "update_column_name('Type', 'TIPO')\n",
    "\n",
    "# Refresh DataFrame\n",
    "result = sheet.values().get(spreadsheetId=SPREADSHEET_ID, range=RANGE_NAME).execute()\n",
    "values = result.get('values', [])\n",
    "df = pd.DataFrame(values[1:], columns=values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c71f732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format dates directly in Google Sheets\n",
    "def format_dates(date_column_name='Date'):\n",
    "    # Get all data\n",
    "    result = sheet.values().get(spreadsheetId=SPREADSHEET_ID, range=RANGE_NAME).execute()\n",
    "    values = result.get('values', [])\n",
    "    \n",
    "    if not values:\n",
    "        print(\"‚ùå No data found\")\n",
    "        return\n",
    "    \n",
    "    headers = values[0]\n",
    "    if date_column_name not in headers:\n",
    "        print(f\"‚ùå '{date_column_name}' column not found\")\n",
    "        return\n",
    "    \n",
    "    col_index = headers.index(date_column_name)\n",
    "    col_letter = chr(65 + col_index)\n",
    "    \n",
    "    # Process dates\n",
    "    updated_values = []\n",
    "    for i, row in enumerate(values[1:], 2):  # Start from row 2\n",
    "        if col_index < len(row) and row[col_index]:\n",
    "            try:\n",
    "                # Parse date (assuming YYYY-MM-DD format)\n",
    "                date_obj = datetime.strptime(row[col_index], \"%Y-%m-%d\")\n",
    "                # Format to DD-MM-YYYY\n",
    "                formatted_date = date_obj.strftime(\"%d-%m-%Y\")\n",
    "                updated_values.append([formatted_date])\n",
    "            except ValueError:\n",
    "                # Keep original if can't parse\n",
    "                updated_values.append([row[col_index]])\n",
    "        else:\n",
    "            updated_values.append([''])\n",
    "    \n",
    "    # Update the entire date column\n",
    "    if updated_values:\n",
    "        sheet.values().update(\n",
    "            spreadsheetId=SPREADSHEET_ID,\n",
    "            range=f'2025!{col_letter}2:{col_letter}{len(updated_values)+1}',\n",
    "            valueInputOption='RAW',\n",
    "            body={'values': updated_values}\n",
    "        ).execute()\n",
    "        \n",
    "        print(f\"‚úÖ Dates formatted to DD-MM-YYYY in column {col_letter}\")\n",
    "\n",
    "# Function usage\n",
    "format_dates('Date')  # or whatever your date column is called"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e68adf3",
   "metadata": {},
   "source": [
    "## Progress\n",
    " \n",
    "\n",
    "‚úî Standard column names\n",
    "\n",
    "‚úî Correct errors in dropdowns\n",
    "\n",
    "‚úî List of countries and regions added as dropdown options in due vars\n",
    "\n",
    "‚úî Last modified by and at (obvious in the sheet, just automated here for reports)\n",
    "\n",
    "‚úî Event Metadata validation complete \n",
    "\n",
    "‚úî Highlights for erroneous entries and/or missing data\n",
    "\n",
    "### Pending\n",
    "\n",
    "? MAD service account\n",
    "\n",
    "? Tool in IC/MAD Unit Github\n",
    "\n",
    "### Next week\n",
    "\n",
    "-> Drugs & Quantities (Type Drugs, Quantity, Weight unit, Seizure_kgs)         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cabfd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dictionary mapping old column names to new names\n",
    "custom_column_names = {\n",
    "    \"Type\": \"event_type\",\n",
    "    \"Time unit\": \"time_unit\",\n",
    "    \"Date\": \"date_1\",\n",
    "    \"Date 2\": \"date_2\",\n",
    "    \"Year\": \"year\",\n",
    "    \"Month\": \"month\",\n",
    "    \"Day\": \"day\",\n",
    "    \"Duration\": \"duration\",\n",
    "    \"Type Drugs\": \"drug_type\",\n",
    "    \"Quantity\": \"quantity\",\n",
    "    \"Weight unit\": \"weight_unit\",\n",
    "    \"seizure_kgs\": \"seizure_kg\",\n",
    "    \"Modus Operandi/place of seizure\": \"modus_operandi/place_seizure\",\n",
    "    \"Sub MO\": \"sub_modus_operandi\",\n",
    "    \"Region\": \"region\",\n",
    "    \"Country\": \"country\",\n",
    "    \"Department/State\": \"department/state\",\n",
    "    \"Municipality/Port\": \"municipality/port\",\n",
    "    \"Origin country\": \"origin_country\",\n",
    "    \"Origin Area\": \"origin_area\",\n",
    "    \"Origin municipality\": \"origin_municipality\",\n",
    "    \"Transit 1/Region\": \"transit_1_region\",\n",
    "    \"Transit 1/country\": \"transit_1_country\",\n",
    "    \"Transit 1/Department\": \"transit_1_department/state\",\n",
    "    \"Transit 1/Municipality\": \"transit_1_municipality/port\",\n",
    "    \"Transit 2/ region\": \"transit_2_region\",\n",
    "    \"Transit 2/ country\": \"transit_2_country\",\n",
    "    \"Transit 2/Department\": \"transit_2_department/state\",\n",
    "    \"Transit 2/municipality/port\": \"transit_2_municipality/port\",\n",
    "    \"Destition - Region\": \"destination_1_region\",\n",
    "    \"Destition - Country\": \"destination_1_country\",\n",
    "    \"Destition - department.state\": \"destination_1_department/state\",\n",
    "    \"Destition - Municipality/Port\": \"destination_1_municipality/port\",\n",
    "    \"Destition 2 - Country\": \"destination_2_country\",\n",
    "    \"Destition 2 - Municipality/Port\": \"destination_2_municipality/port\",\n",
    "    \"Description\": \"description\",\n",
    "    \"Criminal group #1\": \"criminal_group_1\",\n",
    "    \"Criminal group #2\": \"criminal_group_2\",\n",
    "    \"Criminal group #3\": \"criminal_group_3\",\n",
    "    \"Source link\": \"source_link\",\n",
    "    \"Project interested\": \"project_interest\"\n",
    "}\n",
    "\n",
    "# Apply renaming\n",
    "# df.rename(columns=custom_column_names, inplace=True)\n",
    "\n",
    "# Now you can use df with the new column names\n",
    "# print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cf6460c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['municipality', 'department', 'country'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Raw link to your Excel file\n",
    "places_url = \"https://github.com/FelipeVillota/db-check-cocaine-seizures/raw/main/other/list-of-places-ic.xlsx\"\n",
    "\n",
    "# Load the Excel file (defaulting to first sheet, or specify sheet_name if needed)\n",
    "places_df = pd.read_excel(places_url)\n",
    "\n",
    "# Preview the columns to identify the correct one for country list\n",
    "print(places_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65808710",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropdown_options = {\n",
    "    \"event_type\": [\n",
    "        'Crop Eradication', 'Total Crop Cultivation Estimate', 'Price',\n",
    "        'Total Production Estimate', 'Other (explain in Description)', 'Seizure'\n",
    "    ],\n",
    "    \"time_unit\": [\n",
    "        'Multi-Year', 'Multi-Month', 'Month', 'Other (explain in Description)',\n",
    "        'Individual', 'Year'\n",
    "    ],\n",
    "    \"drug_type\": [\n",
    "        'Coca Crops', 'All/Unspecified/Multiple', 'Cocaine',\n",
    "        'Other (explain in Description)', 'Cocaine - Crack', 'Cocaine Base'\n",
    "    ],\n",
    "    \"weight_unit\": [\n",
    "        'Percent', 'Other currency (say which in Description)', 'Hectare',\n",
    "        'Euro', 'Plant', 'USD', 'Other (explain in Description)',\n",
    "        'Pounds (lbs)', 'Kilogram', 'Pounds (¬£)', 'Package'\n",
    "    ],\n",
    "    \"modus_operandi/place_seizure\": [\n",
    "        'River vessel', 'Container', 'Maritime vessel', 'Land', 'Air'\n",
    "    ],\n",
    "    \"region\": [\n",
    "        'Global', 'Central America', 'Asia', 'Europe', 'Oceania',\n",
    "        'South America', 'Caribbean', 'North America', 'Africa'\n",
    "    ],\n",
    "    \"origin_country\": ['Peru', 'Bolivia', '\"\"', 'Colombia'],\n",
    "    \n",
    "    \"transit_1_region\": [\n",
    "        'Global', 'Central America', 'Asia', 'Europe', 'Oceania',\n",
    "        'South America', 'Caribbean', 'North America', 'Africa'\n",
    "    ],\n",
    "    \"transit_2_region\": [\n",
    "        'Global', 'Central America', 'Asia', 'Europe', 'Oceania',\n",
    "        'South America', 'Caribbean', 'North America', 'Africa'\n",
    "    ],\n",
    "    \"destination_1_region\": [\n",
    "        'Central America', 'Asia', 'Europe', 'South America',\n",
    "        'Caribbean', 'North America', 'Australia', 'Africa'\n",
    "    ],\n",
    "    \n",
    "    \"project_interest\": ['Cocaine Pipeline', 'El PACCTO 2.0', 'MAD', 'Dutch']\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv-db-watch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
